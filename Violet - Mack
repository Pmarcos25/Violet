import { NextResponse } from "next/server";
import { getServerSession } from "next-auth/next";
import { authOptions } from "@/lib/auth";
import { applyVideoEdits, createGif } from "@/lib/advanced-video-editing";
import { getUserSubscription } from "@/lib/subscription-service";
import ffmpeg from "fluent-ffmpeg";
import { Storage } from "@google-cloud/storage";
import * as tf from "@tensorflow/tfjs-node";
import * as cocoSsd from "@tensorflow-models/coco-ssd";
import * as faceapi from "face-api.js"; // For face detection
import OpenAI from "openai";
import { Server } from "socket.io";
import rateLimit from "express-rate-limit";
import dotenv from "dotenv";
import winston from "winston";
import { createClient } from "@supabase/supabase-js"; // For social media integration

dotenv.config();

// Initialize all services
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const storage = new Storage({ keyFilename: process.env.GCLOUD_KEY_PATH });
const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_KEY!);
const bucketName = process.env.GCLOUD_BUCKET_NAME!;

// Real-time collaboration server
const io = new Server(process.env.WS_PORT || 3001, { 
  cors: { 
    origin: process.env.ALLOWED_ORIGINS?.split(",") || "*",
    methods: ["GET", "POST"]
  },
  transports: ["websocket"]
});

// Enhanced logging
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || "info",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: "logs/error.log", level: "error" }),
    new winston.transports.File({ filename: "logs/combined.log" }),
  ],
});

// AI Processing Functions
const videoProcessors = {
  async autoCrop(videoPath: string, outputPath: string) {
    const model = await cocoSsd.load();
    const framePath = `frame-${Date.now()}.jpg`;
    
    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .screenshots({ timestamps: [0], filename: framePath, folder: "./" })
        .on("end", resolve)
        .on("error", reject);
    });

    const image = await tf.node.decodeImage(framePath);
    const predictions = await model.detect(image);
    const mainObject = predictions.find(p => ["person", "face"].includes(p.class));

    if (mainObject) {
      const [x, y, width, height] = mainObject.bbox;
      await new Promise((resolve, reject) => {
        ffmpeg(videoPath)
          .videoFilter(`crop=${width}:${height}:${x}:${y}`)
          .output(outputPath)
          .on("end", resolve)
          .on("error", reject)
          .run();
      });
    }
    return outputPath;
  },

  async generateFromText(text: string, outputPath: string) {
    const script = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [{ role: "user", content: `Generate a video script about: ${text}` }],
    });

    const ttsResponse = await fetch(process.env.TTS_SERVICE_URL!, {
      method: "POST",
      body: JSON.stringify({ text: script.choices[0].message.content })
    });

    await new Promise((resolve, reject) => {
      ffmpeg()
        .input("assets/default-background.mp4")
        .input(ttsResponse.body)
        .outputOptions(["-c:v libx264", "-c:a aac", "-shortest"])
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });
    return outputPath;
  },

  async applyPrivacyFeatures(videoPath: string, outputPath: string) {
    await faceapi.nets.tinyFaceDetector.loadFromDisk("models");
    const frameInterval = 0.5; // Process every 0.5 seconds
    
    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .complexFilter([
          {
            filter: "select",
            options: `not(mod(n\\,${frameInterval*30}))`,
            outputs: "frame"
          },
          {
            filter: "boxblur",
            options: "10:5",
            inputs: "frame",
            outputs: "blurred"
          }
        ])
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });
    return outputPath;
  },

  async removeBackground(videoPath: string, outputPath: string) {
    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .videoFilter("chromakey=0x00ff00:0.1:0.2")
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });
    return outputPath;
  },

  async generateCaptions(videoPath: string, outputPath: string) {
    const audioPath = `audio-${Date.now()}.wav`;
    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .output(audioPath)
        .noVideo()
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(audioPath),
      model: "whisper-1",
      response_format: "srt"
    });

    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .input("subtitles=subtitles.srt")
        .output(outputPath)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });
    return outputPath;
  }
};

// Cloud Storage Manager
const cloudService = {
  async upload(filePath: string, folder = "uploads") {
    const destination = `${folder}/${Date.now()}-${path.basename(filePath)}`;
    await storage.bucket(bucketName).upload(filePath, { destination });
    return `https://storage.googleapis.com/${bucketName}/${destination}`;
  },

  async delete(url: string) {
    const filePath = url.split(bucketName)[1].substring(1);
    await storage.bucket(bucketName).file(filePath).delete();
  }
};

// Main API Endpoint
export async function POST(request: Request) {
  try {
    // Authentication & Authorization
    const session = await getServerSession(authOptions);
    if (!session) return NextResponse.json({ error: "Unauthorized" }, { status: 401 });

    const subscription = await getUserSubscription(session.user.id);
    if (!["premium", "enterprise"].includes(subscription.tier)) {
      return NextResponse.json({ error: "Upgrade required" }, { status: 403 });
    }

    // Request Processing
    const { videoPath, options } = await request.json();
    if (!videoPath) return NextResponse.json({ error: "Video path required" }, { status: 400 });

    // Initialize real-time session if needed
    let socketSession;
    if (options.realtime) {
      socketSession = `session-${Date.now()}`;
      io.emit("session-start", { 
        sessionId: socketSession,
        userId: session.user.id
      });
    }

    // Process video with selected features
    let processedPath = videoPath;
    const featureProcessors = [];

    if (options.autoCrop) featureProcessors.push(videoProcessors.autoCrop);
    if (options.generateFromText) featureProcessors.push(() => 
      videoProcessors.generateFromText(options.text, `generated-${Date.now()}.mp4`)
    );
    if (options.privacyBlur) featureProcessors.push(videoProcessors.applyPrivacyFeatures);
    if (options.removeBackground) featureProcessors.push(videoProcessors.removeBackground);
    if (options.generateCaptions) featureProcessors.push(videoProcessors.generateCaptions);

    for (const processor of featureProcessors) {
      processedPath = await processor(processedPath, `processed-${Date.now()}.mp4`);
      if (options.realtime) {
        io.to(socketSession).emit("progress", {
          feature: processor.name,
          previewUrl: await cloudService.upload(processedPath, "previews")
        });
      }
    }

    // Generate additional assets
    const [videoUrl, gifUrl, thumbnailUrl] = await Promise.all([
      cloudService.upload(processedPath),
      options.createGif ? createGif(processedPath).then(gifPath => cloudService.upload(gifPath)) : null,
      options.generateThumbnail ? generateThumbnail(processedPath).then(thumbPath => cloudService.upload(thumbPath)) : null
    ]);

    // Social media integration
    if (options.shareToSocial) {
      await supabase.from("social_media_queue").insert({
        user_id: session.user.id,
        video_url: videoUrl,
        platforms: options.platforms || ["youtube"],
        scheduled_at: new Date()
      });
    }

    // Cleanup temporary files
    if (process.env.NODE_ENV === "production") {
      [processedPath, ...featureProcessors]
        .filter(path => path !== videoPath)
        .forEach(fs.unlinkSync);
    }

    return NextResponse.json({
      success: true,
      videoUrl,
      gifUrl,
      thumbnailUrl,
      socketSession,
      featuresUsed: featureProcessors.map(p => p.name)
    });

  } catch (error) {
    logger.error("Video processing failed", {
      error: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString()
    });
    
    return NextResponse.json(
      { 
        error: "Processing failed",
        requestId: crypto.randomUUID()
      },
      { status: 500 }
    );
  }
}

// WebSocket event handlers
io.on("connection", (socket) => {
  socket.on("join-session", (sessionId) => {
    socket.join(sessionId);
  });

  socket.on("edit-command", (data) => {
    io.to(data.sessionId).emit("command", data.command);
  });
});
